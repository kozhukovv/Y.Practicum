{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отток клиентов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из банка стали уходить клиенты. Требуется спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Требуется построить модель с предельно большим значением *F1*-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59.\n",
    "\n",
    "Источник данных: [https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Выгрузка библиотек и данных для работы"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Выгрузка стандартных билиотек\n",
    "import warnings\n",
    "import random\n",
    "\n",
    "# Выгрузка сторонних библиотек\n",
    "import pandas as pd\n",
    "\n",
    "#Выгрузка модулей библиотек для машинного обучения\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Объявление константы для \"фиксации случайности\"\n",
    "rnd_st = 12345\n",
    "\n",
    "# Настройка игнорирования ошибок\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "random.seed(rnd_st)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Выгрузим данные в переменную df."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('Churn.csv')\n",
    "except:\n",
    "    df = pd.read_csv('/datasets/Churn.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Так как в данных есть столбец, отражающий номер строки, сразу его удалим, так как он нам не понадобится"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df = df.drop('RowNumber', axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Просмотрим общую информацию о данном датафрейме"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "      credit_score  age  tenure    balance  num_of_products  has_credit_card   \n8645           636   20    10.0  124266.86                1                0  \\\n1953           623   21    10.0       0.00                2                0   \n410            709   23    10.0       0.00                2                0   \n5884           552   38    10.0  132271.12                2                1   \n408            668   37    10.0  152958.29                2                1   \n...            ...  ...     ...        ...              ...              ...   \n4722           648   32     0.0       0.00                1                0   \n9523           660   32     0.0  114668.89                1                1   \n6878           651   35     0.0  181821.96                2                0   \n427            702   45     0.0   80793.58                1                1   \n8386           708   41     0.0       0.00                1                1   \n\n      is_active_member  estimated_salary  exited  geography_Germany   \n8645                 0         100566.81       0                  0  \\\n1953                 1         135851.30       0                  0   \n410                  0         129590.18       0                  0   \n5884                 1          46562.02       0                  1   \n408                  1         159585.61       0                  1   \n...                ...               ...     ...                ...   \n4722                 1         117323.31       0                  0   \n9523                 0          84605.00       0                  0   \n6878                 1          36923.67       1                  0   \n427                  1          27474.81       0                  0   \n8386                 0         128400.62       0                  0   \n\n      geography_Spain  gender_Male  \n8645                0            0  \n1953                0            1  \n410                 1            1  \n5884                0            1  \n408                 0            1  \n...               ...          ...  \n4722                0            1  \n9523                0            0  \n6878                0            1  \n427                 0            1  \n8386                0            1  \n\n[10000 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>credit_score</th>\n      <th>age</th>\n      <th>tenure</th>\n      <th>balance</th>\n      <th>num_of_products</th>\n      <th>has_credit_card</th>\n      <th>is_active_member</th>\n      <th>estimated_salary</th>\n      <th>exited</th>\n      <th>geography_Germany</th>\n      <th>geography_Spain</th>\n      <th>gender_Male</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8645</th>\n      <td>636</td>\n      <td>20</td>\n      <td>10.0</td>\n      <td>124266.86</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>100566.81</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1953</th>\n      <td>623</td>\n      <td>21</td>\n      <td>10.0</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>135851.30</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>410</th>\n      <td>709</td>\n      <td>23</td>\n      <td>10.0</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>129590.18</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5884</th>\n      <td>552</td>\n      <td>38</td>\n      <td>10.0</td>\n      <td>132271.12</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>46562.02</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>408</th>\n      <td>668</td>\n      <td>37</td>\n      <td>10.0</td>\n      <td>152958.29</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>159585.61</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4722</th>\n      <td>648</td>\n      <td>32</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>117323.31</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9523</th>\n      <td>660</td>\n      <td>32</td>\n      <td>0.0</td>\n      <td>114668.89</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>84605.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6878</th>\n      <td>651</td>\n      <td>35</td>\n      <td>0.0</td>\n      <td>181821.96</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>36923.67</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>427</th>\n      <td>702</td>\n      <td>45</td>\n      <td>0.0</td>\n      <td>80793.58</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>27474.81</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8386</th>\n      <td>708</td>\n      <td>41</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>128400.62</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='tenure', ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CustomerId       10000 non-null  int64  \n",
      " 1   Surname          10000 non-null  object \n",
      " 2   CreditScore      10000 non-null  int64  \n",
      " 3   Geography        10000 non-null  object \n",
      " 4   Gender           10000 non-null  object \n",
      " 5   Age              10000 non-null  int64  \n",
      " 6   Tenure           9091 non-null   float64\n",
      " 7   Balance          10000 non-null  float64\n",
      " 8   NumOfProducts    10000 non-null  int64  \n",
      " 9   HasCrCard        10000 non-null  int64  \n",
      " 10  IsActiveMember   10000 non-null  int64  \n",
      " 11  EstimatedSalary  10000 non-null  float64\n",
      " 12  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(7), object(3)\n",
      "memory usage: 1015.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "         CustomerId   CreditScore           Age       Tenure        Balance   \ncount  1.000000e+04  10000.000000  10000.000000  9091.000000   10000.000000  \\\nmean   1.569094e+07    650.528800     38.921800     4.997690   76485.889288   \nstd    7.193619e+04     96.653299     10.487806     2.894723   62397.405202   \nmin    1.556570e+07    350.000000     18.000000     0.000000       0.000000   \n25%    1.562853e+07    584.000000     32.000000     2.000000       0.000000   \n50%    1.569074e+07    652.000000     37.000000     5.000000   97198.540000   \n75%    1.575323e+07    718.000000     44.000000     7.000000  127644.240000   \nmax    1.581569e+07    850.000000     92.000000    10.000000  250898.090000   \n\n       NumOfProducts    HasCrCard  IsActiveMember  EstimatedSalary   \ncount   10000.000000  10000.00000    10000.000000     10000.000000  \\\nmean        1.530200      0.70550        0.515100    100090.239881   \nstd         0.581654      0.45584        0.499797     57510.492818   \nmin         1.000000      0.00000        0.000000        11.580000   \n25%         1.000000      0.00000        0.000000     51002.110000   \n50%         1.000000      1.00000        1.000000    100193.915000   \n75%         2.000000      1.00000        1.000000    149388.247500   \nmax         4.000000      1.00000        1.000000    199992.480000   \n\n             Exited  \ncount  10000.000000  \nmean       0.203700  \nstd        0.402769  \nmin        0.000000  \n25%        0.000000  \n50%        0.000000  \n75%        0.000000  \nmax        1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CustomerId</th>\n      <th>CreditScore</th>\n      <th>Age</th>\n      <th>Tenure</th>\n      <th>Balance</th>\n      <th>NumOfProducts</th>\n      <th>HasCrCard</th>\n      <th>IsActiveMember</th>\n      <th>EstimatedSalary</th>\n      <th>Exited</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1.000000e+04</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n      <td>9091.000000</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n      <td>10000.00000</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.569094e+07</td>\n      <td>650.528800</td>\n      <td>38.921800</td>\n      <td>4.997690</td>\n      <td>76485.889288</td>\n      <td>1.530200</td>\n      <td>0.70550</td>\n      <td>0.515100</td>\n      <td>100090.239881</td>\n      <td>0.203700</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>7.193619e+04</td>\n      <td>96.653299</td>\n      <td>10.487806</td>\n      <td>2.894723</td>\n      <td>62397.405202</td>\n      <td>0.581654</td>\n      <td>0.45584</td>\n      <td>0.499797</td>\n      <td>57510.492818</td>\n      <td>0.402769</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.556570e+07</td>\n      <td>350.000000</td>\n      <td>18.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>11.580000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.562853e+07</td>\n      <td>584.000000</td>\n      <td>32.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>51002.110000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.569074e+07</td>\n      <td>652.000000</td>\n      <td>37.000000</td>\n      <td>5.000000</td>\n      <td>97198.540000</td>\n      <td>1.000000</td>\n      <td>1.00000</td>\n      <td>1.000000</td>\n      <td>100193.915000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.575323e+07</td>\n      <td>718.000000</td>\n      <td>44.000000</td>\n      <td>7.000000</td>\n      <td>127644.240000</td>\n      <td>2.000000</td>\n      <td>1.00000</td>\n      <td>1.000000</td>\n      <td>149388.247500</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.581569e+07</td>\n      <td>850.000000</td>\n      <td>92.000000</td>\n      <td>10.000000</td>\n      <td>250898.090000</td>\n      <td>4.000000</td>\n      <td>1.00000</td>\n      <td>1.000000</td>\n      <td>199992.480000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Описание того, что мы имеем (Значения столбцов, количественные/категориальные данные, пропуски, типы данных)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Вывод\n",
    "##### Общая информация\n",
    "Были рассмотрены данные, получена общая информация:\n",
    "Всего строк 10000, столбцов 13, среди них с целевым признаком считается столбец Excited.\n",
    "##### Был проанализирован каждый столбец:\n",
    "\n",
    "|  №  |  Наименование   |                        Описание                         |               Тип данных                |\n",
    "|:---:|:---------------:|:-------------------------------------------------------:|:---------------------------------------:|\n",
    "|  1  |   CustomerId    |         уникальный идентификатор <br/> клиента          | Количественный <br/> и <br/> дискретный |\n",
    "|  2  |     Surname     |                         фамилия                         |             Категориальный              |\n",
    "|  3  |   CreditScore   |                    кредитный рейтинг                    | Количественный <br/> и <br/> дискретный |\n",
    "|  4  |    Geography    |                    страна проживания                    |             Категориальный              |\n",
    "|  5  |     Gender      |                           пол                           |             Категориальный              |\n",
    "|  6  |      Age        |                         возраст                         | Количественный <br/> и <br/> дискретный |\n",
    "|  7  |     Tenure      |    сколько лет человек <br/> является клиентом банка    | Количественный <br/>и <br/> непрерывный |\n",
    "|  8  |     Balance     |                     баланс на счёте                     | Количественный <br/>и <br/> непрерывный |\n",
    "|  9  |  NumOfProducts  | количество продуктов банка, <br/> используемых клиентом | Количественный <br/> и <br/> дискретный |\n",
    "| 10  |    HasCrCard    |              наличие <br/> кредитной карты              |             Категориальный              |\n",
    "| 11  | IsActiveMember  |                   активность клиента                    |             Категориальный              |\n",
    "| 12  | EstimatedSalary |              предполагаемая <br/> зарплата              |       Количественый и непрерывный       |\n",
    "| 13  |     Exited      |                факт ухода <br/> клиента                 |             Категориальный              |\n",
    "В столбце Tenure были обнаружены строки с пропущенными значениями, которые потребуется заполнить"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Подготовка данных"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.0 Перед тем, как мы будем заниматься подготовкой данных для дальнейшего обучения, стоило бы перевести наименования столбцов в корректный вид:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "df.columns = ['customer_id', 'surname', 'credit_score', 'geography', 'gender', 'age', 'tenure', 'balance', 'num_of_products', 'has_credit_card', 'is_active_member', 'estimated_salary', 'exited']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Рассмотрим проблемные столбцы датафрейма:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Столбцы geography и gender"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Столбцы категориальные, пропусков не обнаружено. Рассмотрим существующие уникальные значения"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['France', 'Spain', 'Germany'], dtype=object)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['geography'].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['Female', 'Male'], dtype=object)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gender'].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Для перевода столбца geography из категориального типа в подходящий для машинного обучения вид следует использовать технику прямого кодирования **OHE** (***One-Hot Encoding***), так как значения не отражают порядок или величину (если бы отражали, было бы уместнее использовать порядковое кодирование **OE** (***Ordinal Encoding***). Воспользуемся методом get_dummies из библиотеки pandas с параметром drop_first=True (этот параметр позволяет удалить первый, легко воспроизводимый из двух других, столбец.\n",
    "Для перевода столбца gender уместнее конвертировать каждый пол в цифровой формат, к примеру Female: 0, а Male: 1. Это можно реализовать также через метод get_dummies."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['geography', 'gender'], prefix=['geography', 'gender'], drop_first=True)\n",
    "for i in ['geography_Germany','geography_Spain','gender_Male']:\n",
    "    df[i] = df[i].astype(int)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Перевод столбцов с категориальными данными успешно завершнен."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Столбец tenure\n",
    "В столбце обнаружены пропущенные значения, предлагается заполнить их случайными значениями в диапазоне от 0 до 10, чтобы не портить общее распределение данных"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "count    9091.000000\nmean        4.997690\nstd         2.894723\nmin         0.000000\n25%         2.000000\n50%         5.000000\n75%         7.000000\nmax        10.000000\nName: tenure, dtype: float64"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tenure'].describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tenure'] = df[\"tenure\"].fillna(random.randint(0,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "count    10000.000000\nmean         5.088800\nstd          2.775011\nmin          0.000000\n25%          3.000000\n50%          5.000000\n75%          7.000000\nmax         10.000000\nName: tenure, dtype: float64"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tenure'].describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "После заполнения пропусков среднее арифметическое практически не изменилось, медиана осталась неизменной."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Разделим данные на признаки и целевые признаки (features и target)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "df = df.drop(['customer_id','surname'], axis=1)\n",
    "features = df.drop(['exited'], axis=1)\n",
    "target = df['exited']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Разделение данных на тренировочную, валидационную и тестовую выборки"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Разделим данные с помощью функции train_test_split библиотеки fast_ml"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "features_train, features_valid, target_train, target_valid = train_test_split(features, target, train_size=0.6, random_state=rnd_st, stratify=target)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "features_valid, features_test, target_valid, target_test = train_test_split(features_valid, target_valid, train_size=0.5, random_state=rnd_st, stratify=target_valid)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Проверим размер выборок"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 11)\n",
      "(6000,)\n",
      "(2000, 11)\n",
      "(2000,)\n",
      "(2000, 11)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "for i in [features_train, target_train, features_valid, target_valid, features_test, target_test]:\n",
    "    print(i.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "      credit_score  age  tenure    balance  num_of_products  has_credit_card   \n0              619   42     2.0       0.00                1                1  \\\n1              608   41     1.0   83807.86                1                0   \n2              502   42     8.0  159660.80                3                1   \n3              699   39     1.0       0.00                2                0   \n4              850   43     2.0  125510.82                1                1   \n...            ...  ...     ...        ...              ...              ...   \n9995           771   39     5.0       0.00                2                1   \n9996           516   35    10.0   57369.61                1                1   \n9997           709   36     7.0       0.00                1                0   \n9998           772   42     3.0   75075.31                2                1   \n9999           792   28     6.0  130142.79                1                1   \n\n      is_active_member  estimated_salary  exited  geography_Germany   \n0                    1         101348.88       1                  0  \\\n1                    1         112542.58       0                  0   \n2                    0         113931.57       1                  0   \n3                    0          93826.63       0                  0   \n4                    1          79084.10       0                  0   \n...                ...               ...     ...                ...   \n9995                 0          96270.64       0                  0   \n9996                 1         101699.77       0                  0   \n9997                 1          42085.58       1                  0   \n9998                 0          92888.52       1                  1   \n9999                 0          38190.78       0                  0   \n\n      geography_Spain  gender_Male  \n0                   0            0  \n1                   1            0  \n2                   0            0  \n3                   0            0  \n4                   1            0  \n...               ...          ...  \n9995                0            1  \n9996                0            1  \n9997                0            0  \n9998                0            1  \n9999                0            0  \n\n[10000 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>credit_score</th>\n      <th>age</th>\n      <th>tenure</th>\n      <th>balance</th>\n      <th>num_of_products</th>\n      <th>has_credit_card</th>\n      <th>is_active_member</th>\n      <th>estimated_salary</th>\n      <th>exited</th>\n      <th>geography_Germany</th>\n      <th>geography_Spain</th>\n      <th>gender_Male</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>619</td>\n      <td>42</td>\n      <td>2.0</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>101348.88</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>608</td>\n      <td>41</td>\n      <td>1.0</td>\n      <td>83807.86</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>112542.58</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>502</td>\n      <td>42</td>\n      <td>8.0</td>\n      <td>159660.80</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113931.57</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>699</td>\n      <td>39</td>\n      <td>1.0</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>93826.63</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>850</td>\n      <td>43</td>\n      <td>2.0</td>\n      <td>125510.82</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>79084.10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>771</td>\n      <td>39</td>\n      <td>5.0</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>96270.64</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>516</td>\n      <td>35</td>\n      <td>10.0</td>\n      <td>57369.61</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>101699.77</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>709</td>\n      <td>36</td>\n      <td>7.0</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>42085.58</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>772</td>\n      <td>42</td>\n      <td>3.0</td>\n      <td>75075.31</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>92888.52</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>792</td>\n      <td>28</td>\n      <td>6.0</td>\n      <td>130142.79</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>38190.78</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Вывод: Данные готовы к обучению и дальнейшему масштабированию."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Масштабирование признаков"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Выделим те столбцы, которые требуется масштабировать"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "numeric = ['credit_score',\n",
    "           'age',\n",
    "           'tenure',\n",
    "           'balance',\n",
    "           'estimated_salary'\n",
    "           ]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Масштабируем все полученные features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])\n",
    "for ftrs in [features_train, features_valid, features_test]:\n",
    "    ftrs[numeric] = scaler.transform(ftrs[numeric])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Обучение моделей без балансировки классов"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Обучим три разных вида моделей, для оценки будем использовать метрики f1 и ROC-AUC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "models = {'name':[], 'model':[],'class_weight':[],'f1':[],'auc_roc':[]}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def add_model(name,model,class_weight,f1,auc_roc):\n",
    "    models['name'].append(name)\n",
    "    models['model'].append(model)\n",
    "    models['class_weight'].append(class_weight)\n",
    "    models['f1'].append(f1)\n",
    "    models['auc_roc'].append(auc_roc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Линейная регрессия"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 = 0.3076923076923077, AUC-ROC = 0.7874374938417579\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=rnd_st, solver='liblinear')\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "print(f'f1 = {f1_score(target_valid, predicted_valid)},'\n",
    "      f' AUC-ROC = {roc_auc_score(target_valid, probabilities_one_valid)}')\n",
    "\n",
    "add_model('Логистическая регрессия без балансировки классов', model, 'No', f1_score(target_valid, predicted_valid), roc_auc_score(target_valid, probabilities_one_valid))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Решающее дерево"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth= 1; min_samples_leaf = 1, f1_v = 0.0, roc_auc = 0.697507143560942\n",
      "max_depth= 1; min_samples_leaf = 2, f1_v = 0.0, roc_auc = 0.697507143560942\n",
      "max_depth= 1; min_samples_leaf = 3, f1_v = 0.0, roc_auc = 0.697507143560942\n",
      "max_depth= 1; min_samples_leaf = 4, f1_v = 0.0, roc_auc = 0.697507143560942\n",
      "max_depth= 1; min_samples_leaf = 5, f1_v = 0.0, roc_auc = 0.697507143560942\n",
      "max_depth= 2; min_samples_leaf = 1, f1_v = 0.5203488372093023, roc_auc = 0.7539597497290373\n",
      "max_depth= 2; min_samples_leaf = 2, f1_v = 0.5203488372093023, roc_auc = 0.7539597497290373\n",
      "max_depth= 2; min_samples_leaf = 3, f1_v = 0.5203488372093023, roc_auc = 0.7539597497290373\n",
      "max_depth= 2; min_samples_leaf = 4, f1_v = 0.5203488372093023, roc_auc = 0.7539597497290373\n",
      "max_depth= 2; min_samples_leaf = 5, f1_v = 0.5203488372093023, roc_auc = 0.7539597497290373\n",
      "max_depth= 3; min_samples_leaf = 1, f1_v = 0.5375722543352601, roc_auc = 0.8032503202285939\n",
      "max_depth= 3; min_samples_leaf = 2, f1_v = 0.5375722543352601, roc_auc = 0.8032503202285939\n",
      "max_depth= 3; min_samples_leaf = 3, f1_v = 0.5375722543352601, roc_auc = 0.8032503202285939\n",
      "max_depth= 3; min_samples_leaf = 4, f1_v = 0.5375722543352601, roc_auc = 0.8032503202285939\n",
      "max_depth= 3; min_samples_leaf = 5, f1_v = 0.5375722543352601, roc_auc = 0.8032503202285939\n",
      "max_depth= 4; min_samples_leaf = 1, f1_v = 0.5206349206349208, roc_auc = 0.8198921999704405\n",
      "max_depth= 4; min_samples_leaf = 2, f1_v = 0.5182829888712243, roc_auc = 0.8194287922455414\n",
      "max_depth= 4; min_samples_leaf = 3, f1_v = 0.5198098256735341, roc_auc = 0.8191524411272046\n",
      "max_depth= 4; min_samples_leaf = 4, f1_v = 0.5198098256735341, roc_auc = 0.8191524411272046\n",
      "max_depth= 4; min_samples_leaf = 5, f1_v = 0.5174603174603174, roc_auc = 0.8250243250566559\n",
      "max_depth= 5; min_samples_leaf = 1, f1_v = 0.5454545454545455, roc_auc = 0.849793544930535\n",
      "max_depth= 5; min_samples_leaf = 2, f1_v = 0.5431309904153354, roc_auc = 0.849359388856045\n",
      "max_depth= 5; min_samples_leaf = 3, f1_v = 0.5305466237942122, roc_auc = 0.8476389299438368\n",
      "max_depth= 5; min_samples_leaf = 4, f1_v = 0.5566037735849055, roc_auc = 0.8503747290373437\n",
      "max_depth= 5; min_samples_leaf = 5, f1_v = 0.5534591194968554, roc_auc = 0.8498235663612179\n",
      "\n",
      "Лучшая модель: DecisionTreeClassifier(max_depth=5, min_samples_leaf=4, random_state=12345)\n",
      "f1 лучшей модели: 0.5566037735849055\n",
      "AUC-ROC лучшей модели: 0.8503747290373437\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_f1 = 0\n",
    "best_auc_roc = 0\n",
    "for depth in range(1, 6):\n",
    "    for leaf in range(1,6,1):\n",
    "                model = DecisionTreeClassifier(max_depth=depth,\n",
    "                                               min_samples_leaf=leaf,\n",
    "                                               random_state=rnd_st)\n",
    "                model.fit(features_train, target_train)\n",
    "                predicted_valid = model.predict(features_valid)\n",
    "                f1_v = f1_score(target_valid, predicted_valid)\n",
    "                probabilities_valid = model.predict_proba(features_valid)\n",
    "                probabilities_one_valid = probabilities_valid[:, 1]\n",
    "                auc_roc_of_model = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "                print(f\"max_depth= {depth}; min_samples_leaf = {leaf}, f1_v = {f1_v}, roc_auc = {auc_roc_of_model}\")\n",
    "                if f1_v > best_f1:\n",
    "                    best_f1 = f1_v\n",
    "                    best_model = model\n",
    "                    best_auc_roc = auc_roc_of_model\n",
    "print()\n",
    "print('Лучшая модель:', best_model)\n",
    "print('f1 лучшей модели:', best_f1)\n",
    "print('AUC-ROC лучшей модели:', best_auc_roc)\n",
    "add_model('Решающее дерево без балансировки классов', best_model, 'No', best_f1, best_auc_roc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Случайный лес"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 20, max_depth = 1, min_samples_leaf = 1\n",
      "f1_v = 0.0, auc_roc = 0.8047152120898611\n",
      "n_estimators = 20, max_depth = 1, min_samples_leaf = 2\n",
      "f1_v = 0.0, auc_roc = 0.8047152120898611\n",
      "n_estimators = 20, max_depth = 1, min_samples_leaf = 3\n",
      "f1_v = 0.0, auc_roc = 0.8047152120898611\n",
      "n_estimators = 20, max_depth = 1, min_samples_leaf = 4\n",
      "f1_v = 0.0, auc_roc = 0.8047152120898611\n",
      "n_estimators = 20, max_depth = 1, min_samples_leaf = 5\n",
      "f1_v = 0.0, auc_roc = 0.8047152120898611\n",
      "n_estimators = 20, max_depth = 1, min_samples_leaf = 6\n",
      "f1_v = 0.0, auc_roc = 0.8047152120898611\n",
      "n_estimators = 20, max_depth = 1, min_samples_leaf = 7\n",
      "f1_v = 0.0, auc_roc = 0.8047152120898611\n",
      "n_estimators = 20, max_depth = 1, min_samples_leaf = 8\n",
      "f1_v = 0.0, auc_roc = 0.8047152120898611\n",
      "n_estimators = 20, max_depth = 1, min_samples_leaf = 9\n",
      "f1_v = 0.0, auc_roc = 0.8047152120898611\n",
      "n_estimators = 20, max_depth = 1, min_samples_leaf = 10\n",
      "f1_v = 0.0, auc_roc = 0.8047152120898611\n",
      "n_estimators = 20, max_depth = 1, min_samples_leaf = 11\n",
      "f1_v = 0.0, auc_roc = 0.8047152120898611\n",
      "n_estimators = 20, max_depth = 1, min_samples_leaf = 12\n",
      "f1_v = 0.0, auc_roc = 0.8047152120898611\n",
      "n_estimators = 20, max_depth = 1, min_samples_leaf = 13\n",
      "f1_v = 0.0, auc_roc = 0.8047152120898611\n",
      "n_estimators = 20, max_depth = 1, min_samples_leaf = 14\n",
      "f1_v = 0.0, auc_roc = 0.8047152120898611\n",
      "n_estimators = 20, max_depth = 1, min_samples_leaf = 15\n",
      "f1_v = 0.0, auc_roc = 0.8047152120898611\n",
      "n_estimators = 20, max_depth = 1, min_samples_leaf = 16\n",
      "f1_v = 0.0, auc_roc = 0.8047152120898611\n",
      "n_estimators = 20, max_depth = 1, min_samples_leaf = 17\n",
      "f1_v = 0.0, auc_roc = 0.8047152120898611\n",
      "n_estimators = 20, max_depth = 1, min_samples_leaf = 18\n",
      "f1_v = 0.0, auc_roc = 0.8047152120898611\n",
      "n_estimators = 20, max_depth = 1, min_samples_leaf = 19\n",
      "f1_v = 0.0, auc_roc = 0.8047152120898611\n",
      "n_estimators = 20, max_depth = 1, min_samples_leaf = 20\n",
      "f1_v = 0.0, auc_roc = 0.8047152120898611\n",
      "n_estimators = 20, max_depth = 2, min_samples_leaf = 1\n",
      "f1_v = 0.17002237136465323, auc_roc = 0.82398204256577\n",
      "n_estimators = 20, max_depth = 2, min_samples_leaf = 2\n",
      "f1_v = 0.17002237136465323, auc_roc = 0.82398204256577\n",
      "n_estimators = 20, max_depth = 2, min_samples_leaf = 3\n",
      "f1_v = 0.17002237136465323, auc_roc = 0.82398204256577\n",
      "n_estimators = 20, max_depth = 2, min_samples_leaf = 4\n",
      "f1_v = 0.16964285714285718, auc_roc = 0.8239774238841265\n",
      "n_estimators = 20, max_depth = 2, min_samples_leaf = 5\n",
      "f1_v = 0.16964285714285718, auc_roc = 0.8236125480342891\n",
      "n_estimators = 20, max_depth = 2, min_samples_leaf = 6\n",
      "f1_v = 0.16964285714285718, auc_roc = 0.8236125480342891\n",
      "n_estimators = 20, max_depth = 2, min_samples_leaf = 7\n",
      "f1_v = 0.16964285714285718, auc_roc = 0.8235679007784018\n",
      "n_estimators = 20, max_depth = 2, min_samples_leaf = 8\n",
      "f1_v = 0.16964285714285718, auc_roc = 0.823728015075377\n",
      "n_estimators = 20, max_depth = 2, min_samples_leaf = 9\n",
      "f1_v = 0.16964285714285718, auc_roc = 0.8236772095772984\n",
      "n_estimators = 20, max_depth = 2, min_samples_leaf = 10\n",
      "f1_v = 0.16964285714285718, auc_roc = 0.8236772095772984\n",
      "n_estimators = 20, max_depth = 2, min_samples_leaf = 11\n",
      "f1_v = 0.1729490022172949, auc_roc = 0.8238019139816732\n",
      "n_estimators = 20, max_depth = 2, min_samples_leaf = 12\n",
      "f1_v = 0.1729490022172949, auc_roc = 0.8234970809932014\n",
      "n_estimators = 20, max_depth = 2, min_samples_leaf = 13\n",
      "f1_v = 0.1729490022172949, auc_roc = 0.8232476721844517\n",
      "n_estimators = 20, max_depth = 2, min_samples_leaf = 14\n",
      "f1_v = 0.1729490022172949, auc_roc = 0.8232168809734949\n",
      "n_estimators = 20, max_depth = 2, min_samples_leaf = 15\n",
      "f1_v = 0.1729490022172949, auc_roc = 0.8232168809734949\n",
      "n_estimators = 20, max_depth = 2, min_samples_leaf = 16\n",
      "f1_v = 0.1729490022172949, auc_roc = 0.8249535052714552\n",
      "n_estimators = 20, max_depth = 2, min_samples_leaf = 17\n",
      "f1_v = 0.1729490022172949, auc_roc = 0.8249535052714552\n",
      "n_estimators = 20, max_depth = 2, min_samples_leaf = 18\n",
      "f1_v = 0.1729490022172949, auc_roc = 0.8249535052714552\n",
      "n_estimators = 20, max_depth = 2, min_samples_leaf = 19\n",
      "f1_v = 0.1729490022172949, auc_roc = 0.8249535052714552\n",
      "n_estimators = 20, max_depth = 2, min_samples_leaf = 20\n",
      "f1_v = 0.1729490022172949, auc_roc = 0.8249535052714552\n",
      "n_estimators = 20, max_depth = 3, min_samples_leaf = 1\n",
      "f1_v = 0.25423728813559326, auc_roc = 0.8405592607646073\n",
      "n_estimators = 20, max_depth = 3, min_samples_leaf = 2\n",
      "f1_v = 0.25423728813559326, auc_roc = 0.840261355798601\n",
      "n_estimators = 20, max_depth = 3, min_samples_leaf = 3\n",
      "f1_v = 0.25423728813559326, auc_roc = 0.8401797590895654\n",
      "n_estimators = 20, max_depth = 3, min_samples_leaf = 4\n",
      "f1_v = 0.25423728813559326, auc_roc = 0.8404484124051631\n",
      "n_estimators = 20, max_depth = 3, min_samples_leaf = 5\n",
      "f1_v = 0.25423728813559326, auc_roc = 0.8404530310868065\n",
      "n_estimators = 20, max_depth = 3, min_samples_leaf = 6\n",
      "f1_v = 0.25423728813559326, auc_roc = 0.8400034794068381\n",
      "n_estimators = 20, max_depth = 3, min_samples_leaf = 7\n",
      "f1_v = 0.25423728813559326, auc_roc = 0.8395777909153612\n",
      "n_estimators = 20, max_depth = 3, min_samples_leaf = 8\n",
      "f1_v = 0.25423728813559326, auc_roc = 0.8394553958518081\n",
      "n_estimators = 20, max_depth = 3, min_samples_leaf = 9\n",
      "f1_v = 0.25423728813559326, auc_roc = 0.8393199145235983\n",
      "n_estimators = 20, max_depth = 3, min_samples_leaf = 10\n",
      "f1_v = 0.25423728813559326, auc_roc = 0.8392644903438762\n",
      "n_estimators = 20, max_depth = 3, min_samples_leaf = 11\n",
      "f1_v = 0.25423728813559326, auc_roc = 0.8391751958321017\n",
      "n_estimators = 20, max_depth = 3, min_samples_leaf = 12\n",
      "f1_v = 0.25053078556263275, auc_roc = 0.8386686804118633\n",
      "n_estimators = 20, max_depth = 3, min_samples_leaf = 13\n",
      "f1_v = 0.25053078556263275, auc_roc = 0.8384900913883142\n",
      "n_estimators = 20, max_depth = 3, min_samples_leaf = 14\n",
      "f1_v = 0.25053078556263275, auc_roc = 0.8384685375406444\n",
      "n_estimators = 20, max_depth = 3, min_samples_leaf = 15\n",
      "f1_v = 0.25053078556263275, auc_roc = 0.8384346672085919\n",
      "n_estimators = 20, max_depth = 3, min_samples_leaf = 16\n",
      "f1_v = 0.25423728813559326, auc_roc = 0.8380636331165632\n",
      "n_estimators = 20, max_depth = 3, min_samples_leaf = 17\n",
      "f1_v = 0.25053078556263275, auc_roc = 0.8380359210267022\n",
      "n_estimators = 20, max_depth = 3, min_samples_leaf = 18\n",
      "f1_v = 0.25053078556263275, auc_roc = 0.8384893216080402\n",
      "n_estimators = 20, max_depth = 3, min_samples_leaf = 19\n",
      "f1_v = 0.25053078556263275, auc_roc = 0.8385054869937925\n",
      "n_estimators = 20, max_depth = 3, min_samples_leaf = 20\n",
      "f1_v = 0.24680851063829784, auc_roc = 0.8393199145235983\n",
      "n_estimators = 20, max_depth = 4, min_samples_leaf = 1\n",
      "f1_v = 0.5068493150684932, auc_roc = 0.8569378756527737\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/1r/qjhz2v4d4xjc39blt418n28r0000gn/T/ipykernel_20625/2889090709.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     13\u001B[0m             \u001B[0mpredicted_valid\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfeatures_valid\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m             \u001B[0mf1_v\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mf1_score\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtarget_valid\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpredicted_valid\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m             \u001B[0mprobabilities_valid\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict_proba\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfeatures_valid\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m             \u001B[0mprobabilities_one_valid\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mprobabilities_valid\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m             \u001B[0mauc_roc_of_model\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mroc_auc_score\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtarget_valid\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprobabilities_one_valid\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001B[0m in \u001B[0;36mpredict_proba\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    859\u001B[0m         ]\n\u001B[1;32m    860\u001B[0m         \u001B[0mlock\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mthreading\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mLock\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 861\u001B[0;31m         Parallel(\n\u001B[0m\u001B[1;32m    862\u001B[0m             \u001B[0mn_jobs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mn_jobs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    863\u001B[0m             \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mverbose\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1044\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_iterating\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_original_iterator\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1045\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1046\u001B[0;31m             \u001B[0;32mwhile\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdispatch_one_batch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1047\u001B[0m                 \u001B[0;32mpass\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1048\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36mdispatch_one_batch\u001B[0;34m(self, iterator)\u001B[0m\n\u001B[1;32m    859\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    860\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 861\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dispatch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtasks\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    862\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    863\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36m_dispatch\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    777\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    778\u001B[0m             \u001B[0mjob_idx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jobs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 779\u001B[0;31m             \u001B[0mjob\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply_async\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    780\u001B[0m             \u001B[0;31m# A job can complete so quickly than its callback is\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    781\u001B[0m             \u001B[0;31m# called before we get here, causing self._jobs to\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001B[0m in \u001B[0;36mapply_async\u001B[0;34m(self, func, callback)\u001B[0m\n\u001B[1;32m    206\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mapply_async\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    207\u001B[0m         \u001B[0;34m\"\"\"Schedule a func to be run\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 208\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mImmediateResult\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    209\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcallback\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    210\u001B[0m             \u001B[0mcallback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    570\u001B[0m         \u001B[0;31m# Don't delay the application, to avoid keeping the input\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    571\u001B[0m         \u001B[0;31m# arguments in memory\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 572\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresults\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbatch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    573\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    574\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    260\u001B[0m         \u001B[0;31m# change the default number of processes to -1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    261\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 262\u001B[0;31m             return [func(*args, **kwargs)\n\u001B[0m\u001B[1;32m    263\u001B[0m                     for func, args, kwargs in self.items]\n\u001B[1;32m    264\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    260\u001B[0m         \u001B[0;31m# change the default number of processes to -1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    261\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 262\u001B[0;31m             return [func(*args, **kwargs)\n\u001B[0m\u001B[1;32m    263\u001B[0m                     for func, args, kwargs in self.items]\n\u001B[1;32m    264\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    214\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    215\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mconfig_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 216\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfunction\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    217\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    218\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001B[0m in \u001B[0;36m_accumulate_prediction\u001B[0;34m(predict, X, out, lock)\u001B[0m\n\u001B[1;32m    638\u001B[0m     \u001B[0mcomplains\u001B[0m \u001B[0mthat\u001B[0m \u001B[0mit\u001B[0m \u001B[0mcannot\u001B[0m \u001B[0mpickle\u001B[0m \u001B[0mit\u001B[0m \u001B[0mwhen\u001B[0m \u001B[0mplaced\u001B[0m \u001B[0mthere\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    639\u001B[0m     \"\"\"\n\u001B[0;32m--> 640\u001B[0;31m     \u001B[0mprediction\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcheck_input\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    641\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mlock\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    642\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001B[0m in \u001B[0;36mpredict_proba\u001B[0;34m(self, X, check_input)\u001B[0m\n\u001B[1;32m    970\u001B[0m         \u001B[0mcheck_is_fitted\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    971\u001B[0m         \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_validate_X_predict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcheck_input\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 972\u001B[0;31m         \u001B[0mproba\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtree_\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    973\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    974\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mn_outputs_\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_f1 = 0\n",
    "best_auc_roc = 0\n",
    "\n",
    "for est in [20,50,100]:\n",
    "    for depth in range(1, 21):\n",
    "        for leaf in range(1,21):\n",
    "            model = RandomForestClassifier(n_estimators=est,\n",
    "                                           max_depth=depth,\n",
    "                                           min_samples_leaf = leaf,\n",
    "                                           random_state=rnd_st)\n",
    "            model.fit(features_train, target_train)\n",
    "            predicted_valid = model.predict(features_valid)\n",
    "            f1_v = f1_score(target_valid, predicted_valid)\n",
    "            probabilities_valid = model.predict_proba(features_valid)\n",
    "            probabilities_one_valid = probabilities_valid[:, 1]\n",
    "            auc_roc_of_model = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "            print(f\"n_estimators = {est}, max_depth = {depth}, min_samples_leaf = {leaf}\")\n",
    "            print(f\"f1_v = {f1_v}, auc_roc = {auc_roc_of_model}\")\n",
    "            if f1_v > best_f1:\n",
    "                best_f1 = f1_v\n",
    "                best_model = model\n",
    "                best_auc_roc = auc_roc_of_model\n",
    "\n",
    "print()\n",
    "print('Лучшая модель:', best_model)\n",
    "print('f1 лучшей модели:', best_f1)\n",
    "print('AUC-ROC лучшей модели:', best_auc_roc)\n",
    "add_model('Случайный лес без балансировки классов', best_model, 'No', best_f1, best_auc_roc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Вывод: Лучше всего показала себя модель случайного леса: Ее значение f1 и auc_roc составляет примерно 0.6288 и 0.865 соответственно"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Обучение моделей с учетом балансировки классов"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Обучим модели с параметром class_weight='balabced'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Линейная регрессия"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=rnd_st, solver='liblinear', class_weight='balanced')\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "print(f'f1 = {f1_score(target_valid, predicted_valid)},'\n",
    "      f' AUC-ROC = {roc_auc_score(target_valid, probabilities_one_valid)}')\n",
    "add_model('Логистическая регрессия с учетом балансировки класса', model, 'balanced', f1_score(target_valid, predicted_valid), roc_auc_score(target_valid, probabilities_one_valid))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Решающее дерево"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_model = None\n",
    "best_f1 = 0\n",
    "best_auc_roc = 0\n",
    "\n",
    "for depth in range(1, 6):\n",
    "    for leaf in range(1,6,1):\n",
    "        model = DecisionTreeClassifier(max_depth=depth,\n",
    "                                       min_samples_leaf=leaf,\n",
    "                                       class_weight='balanced',\n",
    "                                       random_state=rnd_st)\n",
    "        model.fit(features_train, target_train)\n",
    "        predicted_valid = model.predict(features_valid)\n",
    "        f1_v = f1_score(target_valid, predicted_valid)\n",
    "        probabilities_valid = model.predict_proba(features_valid)\n",
    "        probabilities_one_valid = probabilities_valid[:, 1]\n",
    "        auc_roc_of_model = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "        print(f\"max_depth= {depth}; min_samples_leaf = {leaf}, f1_v = {f1_v}, roc_auc = {auc_roc_of_model}\")\n",
    "        if f1_v > best_f1:\n",
    "            best_f1 = f1_v\n",
    "            best_model = model\n",
    "            best_auc_roc = auc_roc_of_model\n",
    "\n",
    "print()\n",
    "print('Лучшая модель:', best_model)\n",
    "print('f1 лучшей модели:', best_f1)\n",
    "print('AUC-ROC лучшей модели:', best_auc_roc)\n",
    "add_model('Решающее дерево с учетом балансировки класса', best_model, 'balanced', best_f1, best_auc_roc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Случайный лес"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_model = None\n",
    "best_f1 = 0\n",
    "best_auc_roc = 0\n",
    "\n",
    "# Сначала обучим лес с 20 деревьями-оценщиками и найдем оптимальную глубину\n",
    "for est in [20,50,100]:\n",
    "    for depth in range(1, 21):\n",
    "        for leaf in range(1,21):\n",
    "            model = RandomForestClassifier(n_estimators=est,\n",
    "                                           max_depth=depth,\n",
    "                                           min_samples_leaf = leaf,\n",
    "                                           random_state=rnd_st,\n",
    "                                           class_weight='balanced')\n",
    "            model.fit(features_train, target_train)\n",
    "            predicted_valid = model.predict(features_valid)\n",
    "            f1_v = f1_score(target_valid, predicted_valid)\n",
    "            probabilities_valid = model.predict_proba(features_valid)\n",
    "            probabilities_one_valid = probabilities_valid[:, 1]\n",
    "            auc_roc_of_model = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "            print(f\"n_estimators = {est}, max_depth = {depth}, min_samples_leaf = {leaf}\")\n",
    "            print(f\"f1_v = {f1_v}, auc_roc = {auc_roc_of_model}\")\n",
    "            if f1_v > best_f1:\n",
    "                best_f1 = f1_v\n",
    "                best_model = model\n",
    "                best_auc_roc = auc_roc_of_model\n",
    "\n",
    "print()\n",
    "print('Лучшая модель:', best_model)\n",
    "print('f1 лучшей модели:', best_f1)\n",
    "print('AUC-ROC лучшей модели:', best_auc_roc)\n",
    "add_model('Случайный лес с учетом балансировки класса', best_model, 'balanced', best_f1, best_auc_roc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Вывод: Лучшей моделью машинного обучения также оказалась модель деревьев решений: значения f1 и auc_roc равны примерно 0.658 и 0.8716 соответственно. Результаты оказались немного лучше, чем результаты, полученные без использования параметра балансировки классов class_weight='balanced'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Исследование дисбаланса классов"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Оценим соотношение признаков и целевых признаков"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "target_train.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Видно, что значений класса 1 примерно в 4 раза меньше, чем значений класса 0."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features_train.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Напишем функцию, которая позволит произвести апсемплинг данных для уравновешивания классов."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def upsample(repeat):\n",
    "    features_zeros = features_train[target_train == 0]\n",
    "    features_ones = features_train[target_train == 1]\n",
    "    target_zeros = target_train[target_train == 0]\n",
    "    target_ones = target_train[target_train == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=12345)\n",
    "\n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "\n",
    "features_upsampled, target_upsampled = upsample(4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "target_upsampled.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Видно, что полученные данные после апсемплинга примерно уравновешены в соотношении 1:1."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features_upsampled.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Обучение моделей с учетом апсемплинга"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Обучим модели с учетом апсемплинга тренировочных данных"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Логистическая регрессия"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=rnd_st, solver='liblinear')\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "print(f'f1 = {f1_score(target_valid, predicted_valid)},'\n",
    "      f' AUC-ROC = {roc_auc_score(target_valid, probabilities_one_valid)}')\n",
    "add_model('Логистическая регрессия с учетом апсемплинга', model, 'No', f1_score(target_valid, predicted_valid), roc_auc_score(target_valid, probabilities_one_valid))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Решающее дерево"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_model = None\n",
    "best_f1 = 0\n",
    "best_auc_roc = 0\n",
    "\n",
    "for depth in range(1, 6):\n",
    "    for leaf in range(1,6,1):\n",
    "        model = DecisionTreeClassifier(max_depth=depth,\n",
    "                                       min_samples_leaf=leaf,\n",
    "                                       random_state=rnd_st)\n",
    "        model.fit(features_upsampled, target_upsampled)\n",
    "        predicted_valid = model.predict(features_valid)\n",
    "        f1_v = f1_score(target_valid, predicted_valid)\n",
    "        probabilities_valid = model.predict_proba(features_valid)\n",
    "        probabilities_one_valid = probabilities_valid[:, 1]\n",
    "        auc_roc_of_model = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "        print(f\"max_depth= {depth}; min_samples_leaf = {leaf}, f1_v = {f1_v}, roc_auc = {auc_roc_of_model}\")\n",
    "        if f1_v > best_f1:\n",
    "            best_f1 = f1_v\n",
    "            best_model = model\n",
    "            best_auc_roc = auc_roc_of_model\n",
    "\n",
    "print()\n",
    "print('Лучшая модель:', best_model)\n",
    "print('f1 лучшей модели:', best_f1)\n",
    "print('AUC-ROC лучшей модели:', best_auc_roc)\n",
    "add_model('Решающее дерево с учетом апсемплинга', best_model, 'No', best_f1, best_auc_roc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Случайный лес"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_model = None\n",
    "best_f1 = 0\n",
    "best_auc_roc = 0\n",
    "\n",
    "# Сначала обучим лес с 20 деревьями-оценщиками и найдем оптимальную глубину\n",
    "for est in [20,50,100]:\n",
    "    for depth in range(1, 21):\n",
    "        for leaf in range(1,21):\n",
    "            model = RandomForestClassifier(n_estimators=est,\n",
    "                                           max_depth=depth,\n",
    "                                           min_samples_leaf=leaf,\n",
    "                                           random_state=rnd_st)\n",
    "            model.fit(features_upsampled, target_upsampled)\n",
    "            predicted_valid = model.predict(features_valid)\n",
    "            f1_v = f1_score(target_valid, predicted_valid)\n",
    "            probabilities_valid = model.predict_proba(features_valid)\n",
    "            probabilities_one_valid = probabilities_valid[:, 1]\n",
    "            auc_roc_of_model = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "            print(f\"n_estimators = {est}, max_depth = {depth}, min_samples_leaf = {leaf}\")\n",
    "            print(f\"f1_v = {f1_v}, auc_roc = {auc_roc_of_model}\")\n",
    "            if f1_v > best_f1:\n",
    "                best_f1 = f1_v\n",
    "                best_model = model\n",
    "                best_auc_roc = auc_roc_of_model\n",
    "\n",
    "print()\n",
    "print('Лучшая модель:', best_model)\n",
    "print('f1 лучшей модели:', best_f1)\n",
    "print('AUC-ROC лучшей модели:', best_auc_roc)\n",
    "add_model('Случайный лес с учетом апсемплинга', best_model, 'No', best_f1, best_auc_roc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Вывод: Лучшая модель среди рассмотренных в данном разделе – случайный лес. Полученные значения метрик f1 и auc_roc: 0.655 и 0.874 соответственно."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Рассмотрим сформированный датафрейм и выберем лучшую модель среди всех рассмотренных"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dd = pd.DataFrame(models)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dd.sort_values('f1')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Лучшей моделью оказался случайный лес с методом class_weight='balanced' со следующими гиперпараметрами: max_depth=20, min_samples_leaf=6, n_estimators=50. Обучим модель еще раз и протестируем ее на всех выборках с помощью метрик f1 и auc_roc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(class_weight='balanced',\n",
    "                               max_depth=20,\n",
    "                               min_samples_leaf=6,\n",
    "                               n_estimators=50,\n",
    "                               random_state=12345)\n",
    "model.fit(features_train, target_train)\n",
    "predicted_train = model.predict(features_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "predicted_test = model.predict(features_test)\n",
    "f1_train = f1_score(target_train, predicted_train)\n",
    "f1_valid = f1_score(target_valid, predicted_valid)\n",
    "f1_test = f1_score(target_test, predicted_test)\n",
    "probabilities_train = model.predict_proba(features_train)\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_test = model.predict_proba(features_test)\n",
    "probabilities_one_train = probabilities_train[:, 1]\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "\n",
    "auc_roc_train = roc_auc_score(target_train, probabilities_one_train)\n",
    "auc_roc_valid = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "auc_roc_test = roc_auc_score(target_test, probabilities_one_test)\n",
    "print(f'f1 на тренировочной выборке: {f1_train}')\n",
    "print(f'f1 на валидационной выборке: {f1_valid}')\n",
    "print(f'f1 на тестовой выборке: {f1_test}')\n",
    "print('\\n')\n",
    "print(f'auc_roc на тренировочной выборке: {auc_roc_train}')\n",
    "print(f'auc_roc на валидационной выборке: {auc_roc_valid}')\n",
    "print(f'auc_roc на тестовой выборке: {auc_roc_test}')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Вывод"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "На протяжение работы были построены и обучены модели трех типов: решающее дерево, случайный лес и логистическая регрессия. Был произведен подбор гиперпараметров моделей и выбрана лучшая модель для каждого типа.\n",
    "Были изучены два метода решения проблемы дисбаланса классов: добавление гиперпараметра class_weight='balanced', и апсемплинг данных.\n",
    "Лучшей моделью оказалась модель случайного леса, обученная на тренировочной выборке с добавлением гиперпараметра class_weight='balanced'. Полученные результаты:\n",
    "f1 на тренировочной выборке: 0.81; f1 на валидационной выборке: 0.658; f1 на тестовой выборке: 0.6148,\n",
    "auc_roc на тренировочной выборке: 0.97; auc_roc на валидационной выборке: 0.87; auc_roc на тестовой выборке: 0.855"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[x] Jupyter Notebook открыт\n",
    "[x] Весь код выполняется без ошибок\n",
    "[x] Ячейки с кодом расположены в порядке исполнения\n",
    "[x] Выполнен шаг 1: данные подготовлены\n",
    "[x] Выполнен шаг 2: задача исследована\n",
    "[x] Исследован баланс классов\n",
    "[x] Изучены модели без учёта дисбаланса\n",
    "[x] Написаны выводы по результатам исследования\n",
    "[x] Выполнен шаг 3: учтён дисбаланс\n",
    "[x] Применено несколько способов борьбы с дисбалансом\n",
    "[x] Написаны выводы по результатам исследования\n",
    "[x] Выполнен шаг 4: проведено тестирование\n",
    "[x] Удалось достичь F1-меры не менее 0.59\n",
    "[x] Исследована метрика AUC-ROC"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
